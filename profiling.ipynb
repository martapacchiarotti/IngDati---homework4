{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2waP4Vl9zA4e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COLLEGAMENTO CON GOOGLE DRIVE\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufXiHppX7ZRn",
        "outputId": "8d8e4571-8d88-4306-e70e-52005b590bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distributions(json_data):\n",
        "    name_count = defaultdict(int)\n",
        "    value_count = defaultdict(lambda: defaultdict(int))\n",
        "    measure_count = defaultdict(int)\n",
        "\n",
        "    # Iterare sulla lista principale\n",
        "    for entry in json_data:\n",
        "        # Verifica se l'entry è un dizionario con la chiave \"errore\"\n",
        "        if isinstance(entry, dict) and \"errore\" in entry:\n",
        "            print(f\"Errore nel file: {entry['errore']}\")\n",
        "            continue  # Salta questa voce e passa alla successiva\n",
        "        # Se non c'è un errore, procediamo con il calcolo delle distribuzioni\n",
        "        if isinstance(entry, dict):\n",
        "        # Ogni entry è un dizionario\n",
        "          for key, item in entry.items():\n",
        "            # Distribuzione dei \"name\" in specifications\n",
        "            for spec_key, spec in item.get(\"specifications\", {}).items():\n",
        "                name = spec[\"name\"]\n",
        "                # Check if name is a list and convert it to a string if necessary\n",
        "                if isinstance(name, list):\n",
        "                    name = str(name)  # or any other appropriate string representation\n",
        "\n",
        "                value = spec[\"value\"]\n",
        "                name_count[name] += 1\n",
        "                value_count[name][value] += 1\n",
        "\n",
        "            # Distribuzione delle \"Measure\"\n",
        "            measure = item.get(\"Measure\", \"\")\n",
        "            if measure:\n",
        "                measure_count[measure] += 1\n",
        "        else:\n",
        "            print(\"Trovata una voce non valida (non un dizionario):\", entry)\n",
        "\n",
        "    return name_count, value_count, measure_count\n",
        "\n",
        "# Funzioni per aggregare i dati\n",
        "def aggregate_dicts(global_dict, local_dict):\n",
        "    for key, count in local_dict.items():\n",
        "        global_dict[key] += count\n",
        "\n",
        "def aggregate_nested_dicts(global_dict, local_dict):\n",
        "    for outer_key, inner_dict in local_dict.items():\n",
        "        for inner_key, count in inner_dict.items():\n",
        "            global_dict[outer_key][inner_key] += count\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0_svViRJzVZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PROFILING PRIMA DELL'ALLINEAMENTO\n",
        "# Percorso alla cartella con i file JSON\n",
        "input_folder = \"/content/drive/My Drive/Ingegneria-dei-dati/extracted_claims\"\n",
        "# Percorso della cartella per salvare i file delle distribuzioni\n",
        "distributions_folder = \"/content/drive/My Drive/Ingegneria-dei-dati/distributions\"\n",
        "# Creare la cartella di output se non esiste\n",
        "os.makedirs(distributions_folder, exist_ok=True)\n",
        "\n",
        "# Percorsi dei file di output\n",
        "name_profiling_csv = os.path.join(distributions_folder, \"name_profiling.csv\")\n",
        "value_profiling_csv = os.path.join(distributions_folder, \"value_profiling.csv\")\n",
        "metrics_profiling_csv = os.path.join(distributions_folder, \"metrics_profiling.csv\")\n",
        "\n",
        "# Variabili per aggregare i risultati di tutti i file json\n",
        "all_name_counts = defaultdict(int)\n",
        "all_value_counts = defaultdict(lambda: defaultdict(int))\n",
        "all_measure_counts = defaultdict(int)\n",
        "\n",
        "# Iterare sui file JSON nella cartella\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.endswith(\".json\"):\n",
        "        file_path = os.path.join(input_folder, file_name)\n",
        "        with open(file_path, \"r\") as file:\n",
        "            data = json.load(file)\n",
        "            name_count, value_count, measure_count = calculate_distributions(data)\n",
        "\n",
        "            # Aggregare i risultati dei singoli file json per ottenere le distribuzioni globali\n",
        "            aggregate_dicts(all_name_counts, name_count)\n",
        "            aggregate_nested_dicts(all_value_counts, value_count)\n",
        "            aggregate_dicts(all_measure_counts, measure_count)\n",
        "\n",
        "# Preparare i dati per il file name_profiling.csv\n",
        "name_rows = [{\"Name\": name, \"Count\": count} for name, count in all_name_counts.items()]\n",
        "name_df = pd.DataFrame(name_rows)\n",
        "name_df.to_csv(name_profiling_csv, index=False)\n",
        "\n",
        "# Preparare i dati per il file value_profiling.csv\n",
        "value_rows = [\n",
        "    {\"Name\": name, \"Value\": value, \"Count\": count}\n",
        "    for name, values in all_value_counts.items()\n",
        "    for value, count in values.items()\n",
        "]\n",
        "value_df = pd.DataFrame(value_rows)\n",
        "value_df.to_csv(value_profiling_csv, index=False)\n",
        "\n",
        "# Preparare i dati per il file metrics_profiling.csv\n",
        "metric_rows = [{\"Measure\": measure, \"Count\": count} for measure, count in all_measure_counts.items()]\n",
        "metric_df = pd.DataFrame(metric_rows)\n",
        "metric_df.to_csv(metrics_profiling_csv, index=False)\n",
        "\n",
        "print(f\"File salvati: {name_profiling_csv}, {value_profiling_csv}, {metrics_profiling_csv}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk0nIb2p2fL9",
        "outputId": "0f3eef41-1b5a-432f-9786-0dfca5391020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File salvati: /content/drive/My Drive/Ingegneria-dei-dati/distributions/name_profiling.csv, /content/drive/My Drive/Ingegneria-dei-dati/distributions/value_profiling.csv, /content/drive/My Drive/Ingegneria-dei-dati/distributions/metrics_profiling.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROFILING DOPO L'ALLINEAMENTO\n",
        "\n",
        "# Percorso alla cartella con i file JSON\n",
        "input_folder = \"/content/drive/My Drive/Ingegneria-dei-dati/alligned_claims\"\n",
        "# Percorso della cartella per salvare i file delle distribuzioni\n",
        "distributions_folder = \"/content/drive/My Drive/Ingegneria-dei-dati/alligned_distributions\"\n",
        "# Percorsi dei file di output\n",
        "name_profiling_csv = os.path.join(distributions_folder, \"alligned_name_profiling.csv\")\n",
        "value_profiling_csv = os.path.join(distributions_folder, \"alligned_value_profiling.csv\")\n",
        "metrics_profiling_csv = os.path.join(distributions_folder, \"alligned_metrics_profiling.csv\")\n",
        "\n",
        "# Variabili per aggregare i risultati di tutti i file json\n",
        "all_name_counts = defaultdict(int)\n",
        "all_value_counts = defaultdict(lambda: defaultdict(int))\n",
        "all_measure_counts = defaultdict(int)\n",
        "\n",
        "# Iterare sui file JSON nella cartella\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.endswith(\".json\"):\n",
        "        file_path = os.path.join(input_folder, file_name)\n",
        "        with open(file_path, \"r\") as file:\n",
        "            data = json.load(file)\n",
        "            print(json.dumps(data, indent=4))\n",
        "            name_count, value_count, measure_count = calculate_distributions(data)\n",
        "\n",
        "            # Aggregare i risultati dei singoli file json per ottenere le distribuzioni globali\n",
        "            aggregate_dicts(all_name_counts, name_count)\n",
        "            aggregate_nested_dicts(all_value_counts, value_count)\n",
        "            aggregate_dicts(all_measure_counts, measure_count)\n",
        "\n",
        "# Preparare i dati per il file name_profiling.csv\n",
        "name_rows = [{\"Name\": name, \"Count\": count} for name, count in all_name_counts.items()]\n",
        "name_df = pd.DataFrame(name_rows)\n",
        "name_df.to_csv(name_profiling_csv, index=False)\n",
        "\n",
        "# Preparare i dati per il file value_profiling.csv\n",
        "value_rows = [\n",
        "    {\"Name\": name, \"Value\": value, \"Count\": count}\n",
        "    for name, values in all_value_counts.items()\n",
        "    for value, count in values.items()\n",
        "]\n",
        "value_df = pd.DataFrame(value_rows)\n",
        "value_df.to_csv(value_profiling_csv, index=False)\n",
        "\n",
        "# Preparare i dati per il file metrics_profiling.csv\n",
        "metric_rows = [{\"Measure\": measure, \"Count\": count} for measure, count in all_measure_counts.items()]\n",
        "metric_df = pd.DataFrame(metric_rows)\n",
        "metric_df.to_csv(metrics_profiling_csv, index=False)\n",
        "\n",
        "print(f\"File salvati: {name_profiling_csv}, {value_profiling_csv}, {metrics_profiling_csv}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TFnpatTjTn3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}